# -*- coding: utf-8 -*-
import json
import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,4,5"

import argparse
import warnings
import numpy as np
import pandas as pd
from sklearn.metrics import recall_score
from autogluon.multimodal import MultiModalPredictor

warnings.filterwarnings("ignore")

# ----------------------------- æ•°æ®é¢„å¤„ç†å·¥å…·å‡½æ•° ----------------------------- #

def clean_func(func: str) -> str:
    """ç®€å•å»æ‰é¦–å°¾ç©ºæ ¼ / ç©ºè¡Œï¼Œä¿æŒä¸åŸè„šæœ¬ä¸€è‡´"""
    lines = [ln.strip() for ln in func.split("\n") if ln.strip()]
    return "\n".join(lines)

def add_sample_weight(df: pd.DataFrame, pos_weight: float) -> pd.DataFrame:
    """åœ¨ DataFrame ä¸­æ–°å¢ 'weight' åˆ—â€”â€”æ­£ä¾‹=pos_weightï¼Œè´Ÿä¾‹=1"""
    df = df.copy()
    df["weight"] = df["target"].apply(lambda x: pos_weight if x == 1 else 1)
    return df

# ----------------------------- ä¸»è®­ç»ƒæµç¨‹ ----------------------------- #

def trainer(train_pd: pd.DataFrame, val_pd: pd.DataFrame, test_pd: pd.DataFrame, args):
    
    selected_model = args.model_name
    model_path = f"../output_{selected_model.split('/')[-1]}_seed{args.seed}/{args.cwe}"

    if os.path.exists(model_path):
        predictor = MultiModalPredictor.load(model_path)
        predictor.set_num_gpus(1)
        print("æ£€æµ‹åˆ°å·²è®­ç»ƒæ¨¡å‹ï¼Œç›´æ¥åŠ è½½å®Œæˆï¼")
        # åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—f1,precision,recall,accuracyå¹¶å†™å…¥eval_result.json
        eval_result = predictor.evaluate(test_pd,metrics = ['f1','average_precision','precision','recall'])
        print(eval_result)
        with open(f"{model_path}/eval_result.json", "w") as f:
            json.dump(eval_result, f)

        # ä¿å­˜æœ€ä¼˜é˜ˆå€¼ï¼ˆåœ¨éªŒè¯é›†ä¸Šé€¼è¿‘ target_recallï¼‰
        save_best_threshold(predictor, val_pd, args.target_recall, model_path)
    else:
        os.makedirs(model_path, exist_ok=True)
        print("ğŸ”¹ å¼€å§‹è®­ç»ƒ ...")
        predictor = MultiModalPredictor(
            label='target', eval_metric="f1", path=model_path
        )
        predictor.fit(
            train_data=train_pd,
            tuning_data=val_pd,
            seed=args.seed,
            hyperparameters={
                "model.hf_text.checkpoint_name": selected_model,
                "env.precision": "bf16-mixed", 
                "optim.loss_func": "focal_loss",
                "optim.focal_loss.gamma": 2.0, 
                "optim.focal_loss.alpha": [0.058, 0.942],
            },
        )
        predictor.set_num_gpus(1)
        # åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—f1,precision,recall,accuracyå¹¶å†™å…¥eval_result.json
        eval_result = predictor.evaluate(test_pd,metrics = ['f1','average_precision','precision','recall'])
        print(eval_result)
        with open(f"{model_path}/eval_result.json", "w") as f:
            json.dump(eval_result, f)

        # ä¿å­˜æœ€ä¼˜é˜ˆå€¼ï¼ˆåœ¨éªŒè¯é›†ä¸Šé€¼è¿‘ target_recallï¼‰
        save_best_threshold(predictor, val_pd, args.target_recall, model_path)

    # ---------------------------- æ¨ç†é˜¶æ®µ ---------------------------- #
    print("\n>>> åœ¨éªŒè¯é›†ä¸Šæ¨ç†å¹¶ä¿å­˜æ¦‚ç‡ ...")
    val_pred_proba = predictor.predict_proba(val_pd[["function"]], as_multiclass=False, as_pandas=False)
    np.save(os.path.join(model_path, "val_pred_proba.npy"), val_pred_proba)
    print("\n>>> åœ¨æµ‹è¯•é›†ä¸Šæ¨ç†å¹¶ä¿å­˜æ¦‚ç‡ ...")
    test_pred_proba = predictor.predict_proba(test_pd[["function"]], as_multiclass=False, as_pandas=False)
    np.save(os.path.join(model_path, "test_pred_proba.npy"), test_pred_proba)

    # æ ¹æ®é˜ˆå€¼å¾—åˆ°æœ€ç»ˆæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
    th_path = os.path.join(model_path, "best_threshold.txt")
    if os.path.exists(th_path):
        best_th = float(open(th_path).read().strip())
        test_pred_label = (test_pred_proba >= best_th).astype(int)
        np.save(os.path.join(model_path, "test_pred_label.npy"), test_pred_label)
        print(f"å·²åº”ç”¨ best_th={best_th:.4f} ç”Ÿæˆ test_pred_label.npy")


# ---------------------------------------------------------------------------- #
#                               é˜ˆ å€¼ å¤„ ç†                                     #
# ---------------------------------------------------------------------------- #

def save_best_threshold(predictor: MultiModalPredictor, val_pd: pd.DataFrame, target_recall: float, model_path: str):

    print("\n>>> é˜ˆå€¼æ‰«æä»¥æ»¡è¶³ç›®æ ‡å¬å›ç‡ ...")
    proba = predictor.predict_proba(val_pd[["function"]], as_multiclass=False, as_pandas=False)
    y_true = val_pd["target"].values

    thresholds = np.linspace(0.5, 0.0, 501)  # 0~0.5 æ­¥é•¿0.001
    best_th = 0.5
    for th in thresholds:
        recall = recall_score(y_true, proba >= th)
        if recall >= target_recall:
            best_th = th
            break

    with open(os.path.join(model_path, "best_threshold.txt"), "w") as f:
        f.write(str(best_th))

    print(f"æœ€ä½³é˜ˆå€¼ = {best_th:.4f} (æ»¡è¶³ recall â‰¥ {target_recall})\n")


# ----------------------------- CLI & ä¸»å…¥å£ ----------------------------- #

def parse_args():
    parser = argparse.ArgumentParser(description="CodeBERT äºŒåˆ†ç±»é«˜å¬å›è®­ç»ƒè„šæœ¬")
    parser.add_argument("--cwe", type=str, default="binary", help="cwe name")
    parser.add_argument("--model_name", type=str, default="microsoft/codebert-base", help="é¢„è®­ç»ƒæ¨¡å‹åç§°")
    parser.add_argument("--seed", type=int, default=0, help="éšæœºç§å­")
    parser.add_argument("--train_file", type=str, default="../dataset-MoE/train_cwe.parquet")
    parser.add_argument("--test_file", type=str, default="../dataset-MoE/test_cwe.parquet")
    parser.add_argument("--val_file", type=str, default="../dataset-MoE/val_cwe.parquet")

    parser.add_argument("--pos_weight", type=float, default=1.0, help="æ­£ä¾‹æ ·æœ¬æƒé‡ (loss åŠ æƒ)")
    parser.add_argument("--target_recall", type=float, default=0.95, help="é˜ˆå€¼æœç´¢ç›®æ ‡å¬å›ç‡")

    return parser.parse_args()

def main():
    args = parse_args()

    train_pd = pd.read_parquet(args.train_file)
    val_pd = pd.read_parquet(args.val_file)
    test_pd = pd.read_parquet(args.test_file)

    for df in (train_pd, val_pd, test_pd):
        df["function"] = df["function"].apply(clean_func)

    # æ·»åŠ æ ·æœ¬æƒé‡
    # train_pd = add_sample_weight(train_pd[["function", "target"]], args.pos_weight)
    # val_pd = add_sample_weight(val_pd[["function", "target"]], args.pos_weight)
    # test_pd = add_sample_weight(test_pd[["function", "target"]], args.pos_weight)
    # trainer(train_pd, val_pd, test_pd, args)

    # åªç”¨focal loss
    trainer(train_pd[["function", "target"]], val_pd[["function", "target"]], test_pd[["function", "target"]], args)


if __name__ == "__main__":
    main()
